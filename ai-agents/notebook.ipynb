{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Azure AI Agent Service </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://learn.microsoft.com/en-us/python/api/overview/azure/ai-projects-readme?view=azure-python-preview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Deploying an agent with infrastructure as code</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Creating a simple agent</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\ngrassetto\\onedrive - microsoft\\desktop\\azure-notebooks\\.venv\\lib\\site-packages (24.0)\n",
      "Collecting pip\n",
      "  Downloading pip-25.0.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Downloading pip-25.0.1-py3-none-any.whl (1.8 MB)\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.0/1.8 MB 279.3 kB/s eta 0:00:07\n",
      "   -- ------------------------------------- 0.1/1.8 MB 581.0 kB/s eta 0:00:04\n",
      "   -------- ------------------------------- 0.4/1.8 MB 1.8 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.1/1.8 MB 4.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.8/1.8 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.8/1.8 MB 5.9 MB/s eta 0:00:00\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 24.0\n",
      "    Uninstalling pip-24.0:\n",
      "      Successfully uninstalled pip-24.0\n",
      "Successfully installed pip-25.0.1\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\ngrassetto\\onedrive - microsoft\\desktop\\azure-notebooks\\.venv\\lib\\site-packages (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "# !pip install azure-ai-projects\n",
    "# !pip install azure-identity\n",
    "# !python.exe -m pip install --upgrade pip\n",
    "# !pip install python-dotenv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created agent, agent ID: asst_4bUsle9VtUUKHM4R9qt8pIaz\n",
      "Created thread, thread ID: thread_vGkUyo9iWrXGsxghNmiiLGGm\n",
      "Created message, message ID: msg_rF3rn31nVYcGzXxpsKXK3PYN\n",
      "Run finished with status: RunStatus.COMPLETED\n",
      "Messages: {'object': 'list', 'data': [{'id': 'msg_BKN7qvTWN44Ts8dEOuccCSJd', 'object': 'thread.message', 'created_at': 1741345692, 'assistant_id': 'asst_4bUsle9VtUUKHM4R9qt8pIaz', 'thread_id': 'thread_vGkUyo9iWrXGsxghNmiiLGGm', 'run_id': 'run_BhbbS4oyrULVUBFxeWboN93b', 'role': 'assistant', 'content': [{'type': 'image_file', 'image_file': {'file_id': 'assistant-3u5c14EihWjQLXQiwZTouH'}}, {'type': 'text', 'text': {'value': \"I've created the bar chart for the operating profits of the companies. You can download it using the link below:\\n\\n[Download the operating profit bar chart](sandbox:/mnt/data/operating_profit_bar_chart.png)\", 'annotations': [{'type': 'file_path', 'text': 'sandbox:/mnt/data/operating_profit_bar_chart.png', 'start_index': 156, 'end_index': 204, 'file_path': {'file_id': 'assistant-9uusGSM41GjT3tGm2jF8v9'}}]}}], 'attachments': [{'file_id': 'assistant-9uusGSM41GjT3tGm2jF8v9', 'tools': [{'type': 'code_interpreter'}]}], 'metadata': {}}, {'id': 'msg_rF3rn31nVYcGzXxpsKXK3PYN', 'object': 'thread.message', 'created_at': 1741345681, 'assistant_id': None, 'thread_id': 'thread_vGkUyo9iWrXGsxghNmiiLGGm', 'run_id': None, 'role': 'user', 'content': [{'type': 'text', 'text': {'value': 'Could you please create a bar chart for the operating profit using the following data and provide the file to me? Company A: $1.2 million, Company B: $2.5 million, Company C: $3.0 million, Company D: $1.8 million', 'annotations': []}}], 'attachments': [], 'metadata': {}}], 'first_id': 'msg_BKN7qvTWN44Ts8dEOuccCSJd', 'last_id': 'msg_rF3rn31nVYcGzXxpsKXK3PYN', 'has_more': False}\n",
      "Last Message: I've created the bar chart for the operating profits of the companies. You can download it using the link below:\n",
      "\n",
      "[Download the operating profit bar chart](sandbox:/mnt/data/operating_profit_bar_chart.png)\n",
      "Image File ID: assistant-3u5c14EihWjQLXQiwZTouH\n",
      "Saved image file to: c:\\Users\\ngrassetto\\OneDrive - Microsoft\\Desktop\\azure-notebooks\\ai-agents\\assistant-3u5c14EihWjQLXQiwZTouH_image_file.png\n",
      "File Paths:\n",
      "Type: file_path\n",
      "Text: sandbox:/mnt/data/operating_profit_bar_chart.png\n",
      "File ID: assistant-9uusGSM41GjT3tGm2jF8v9\n",
      "Start Index: 156\n",
      "End Index: 204\n",
      "Deleted agent\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.ai.projects.models import CodeInterpreterTool\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from typing import Any\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Create an Azure AI Client from a connection string, copied from your Azure AI Foundry project.\n",
    "# At the moment, it should be in the format \"<HostName>;<AzureSubscriptionId>;<ResourceGroup>;<ProjectName>\"\n",
    "# HostName can be found by navigating to your discovery_url and removing the leading \"https://\" and trailing \"/discovery\"\n",
    "# To find your discovery_url, run the CLI command: az ml workspace show -n {project_name} --resource-group {resource_group_name} --query discovery_url\n",
    "# Project Connection example: eastus.api.azureml.ms;12345678-abcd-1234-9fc6-62780b3d3e05;my-resource-group;my-project-name\n",
    "# Customer needs to login to Azure subscription via Azure CLI and set the environment variables\n",
    "\n",
    "project_client = AIProjectClient.from_connection_string(\n",
    "    credential=DefaultAzureCredential(), conn_str=os.environ.get(\"PROJECT_CONNECTION_STRING\")\n",
    ")\n",
    "\n",
    "with project_client:\n",
    "    # Create an instance of the CodeInterpreterTool\n",
    "    code_interpreter = CodeInterpreterTool()\n",
    "\n",
    "    # The CodeInterpreterTool needs to be included in creation of the agent\n",
    "    agent = project_client.agents.create_agent(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        name=\"my-agent\",\n",
    "        instructions=\"You are helpful agent\",\n",
    "        tools=code_interpreter.definitions,\n",
    "        tool_resources=code_interpreter.resources,\n",
    "    )\n",
    "    # print(f\"Created agent, agent ID: {agent.id}\")\n",
    "\n",
    "    # Create a thread\n",
    "    thread = project_client.agents.create_thread()\n",
    "    print(f\"Created thread, thread ID: {thread.id}\")\n",
    "\n",
    "    # Create a message\n",
    "    message = project_client.agents.create_message(\n",
    "        thread_id=thread.id,\n",
    "        role=\"user\",\n",
    "        content=\"Could you please create a bar chart for the operating profit using the following data and provide the file to me? Company A: $1.2 million, Company B: $2.5 million, Company C: $3.0 million, Company D: $1.8 million\",\n",
    "    )\n",
    "    print(f\"Created message, message ID: {message.id}\")\n",
    "\n",
    "    # Run the agent\n",
    "    run = project_client.agents.create_and_process_run(thread_id=thread.id, assistant_id=agent.id)\n",
    "    print(f\"Run finished with status: {run.status}\")\n",
    "\n",
    "    if run.status == \"failed\":\n",
    "        # Check if you got \"Rate limit is exceeded.\", then you want to get more quota\n",
    "        print(f\"Run failed: {run.last_error}\")\n",
    "\n",
    "    # Get messages from the thread\n",
    "    messages = project_client.agents.list_messages(thread_id=thread.id)\n",
    "    print(f\"Messages: {messages}\")\n",
    "\n",
    "    # Get the last message from the sender\n",
    "    last_msg = messages.get_last_text_message_by_role(\"assistant\")\n",
    "    if last_msg:\n",
    "        print(f\"Last Message: {last_msg.text.value}\")\n",
    "\n",
    "    # Generate an image file for the bar chart\n",
    "    for image_content in messages.image_contents:\n",
    "        print(f\"Image File ID: {image_content.image_file.file_id}\")\n",
    "        file_name = f\"{image_content.image_file.file_id}_image_file.png\"\n",
    "        project_client.agents.save_file(file_id=image_content.image_file.file_id, file_name=file_name)\n",
    "        print(f\"Saved image file to: {Path.cwd() / file_name}\")\n",
    "\n",
    "    # Print the file path(s) from the messages\n",
    "    for file_path_annotation in messages.file_path_annotations:\n",
    "        print(f\"File Paths:\")\n",
    "        print(f\"Type: {file_path_annotation.type}\")\n",
    "        print(f\"Text: {file_path_annotation.text}\")\n",
    "        print(f\"File ID: {file_path_annotation.file_path.file_id}\")\n",
    "        print(f\"Start Index: {file_path_annotation.start_index}\")\n",
    "        print(f\"End Index: {file_path_annotation.end_index}\")\n",
    "        project_client.agents.save_file(file_id=file_path_annotation.file_path.file_id, file_name=Path(file_path_annotation.text).name)\n",
    "\n",
    "    # Delete the agent once done\n",
    "    project_client.agents.delete_agent(agent.id)\n",
    "    print(\"Deleted agent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Using knowledge tools</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Grounding with Bing Search</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an Azure AI Client from a connection string, copied from your Azure AI Foundry project.</br>\n",
    "At the moment, it should be in the format \"<HostName>;<AzureSubscriptionId>;<ResourceGroup>;<HubName>\"</br>\n",
    "You need to log into your Azure subscription via the Azure CLI and set the relevant environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.projects.models import BingGroundingTool\n",
    "\n",
    "project_client = AIProjectClient.from_connection_string(\n",
    "    credential=DefaultAzureCredential(),\n",
    "    conn_str=os.environ[\"PROJECT_CONNECTION_STRING\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "HttpResponseError",
     "evalue": "(model_not_found_or_ready) The model deployment provided for this resource does not exist or is not yet ready. If you created the deployment within the last 5 minutes, please wait a moment and try again.\nCode: model_not_found_or_ready\nMessage: The model deployment provided for this resource does not exist or is not yet ready. If you created the deployment within the last 5 minutes, please wait a moment and try again.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHttpResponseError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Create agent with the bing tool and process assistant run\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m project_client:\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     agent = \u001b[43mproject_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43magents\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_agent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmy-assistant\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m        \u001b[49m\u001b[43minstructions\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mYou are a helpful assistant\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbing\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdefinitions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mx-ms-enable-preview\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrue\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCreated agent, ID: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00magent.id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ngrassetto\\OneDrive - Microsoft\\Desktop\\azure-notebooks\\.venv\\Lib\\site-packages\\azure\\core\\tracing\\decorator.py:105\u001b[39m, in \u001b[36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    103\u001b[39m span_impl_type = settings.tracing_implementation()\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m span_impl_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[32m    108\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m merge_span \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m passed_in_parent:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ngrassetto\\OneDrive - Microsoft\\Desktop\\azure-notebooks\\.venv\\Lib\\site-packages\\azure\\ai\\projects\\operations\\_patch.py:1062\u001b[39m, in \u001b[36mAgentsOperations.create_agent\u001b[39m\u001b[34m(self, body, model, name, description, instructions, tools, tool_resources, toolset, temperature, top_p, response_format, metadata, content_type, **kwargs)\u001b[39m\n\u001b[32m   1059\u001b[39m     tools = toolset.definitions\n\u001b[32m   1060\u001b[39m     tool_resources = toolset.resources\n\u001b[32m-> \u001b[39m\u001b[32m1062\u001b[39m new_agent = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_agent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1063\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1064\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1065\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1066\u001b[39m \u001b[43m    \u001b[49m\u001b[43minstructions\u001b[49m\u001b[43m=\u001b[49m\u001b[43minstructions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1067\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1068\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtool_resources\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtool_resources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1069\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1070\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1071\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1072\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1073\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1074\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1076\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m toolset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1077\u001b[39m     \u001b[38;5;28mself\u001b[39m._toolset[new_agent.id] = toolset\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ngrassetto\\OneDrive - Microsoft\\Desktop\\azure-notebooks\\.venv\\Lib\\site-packages\\azure\\core\\tracing\\decorator.py:105\u001b[39m, in \u001b[36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    103\u001b[39m span_impl_type = settings.tracing_implementation()\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m span_impl_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[32m    108\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m merge_span \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m passed_in_parent:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ngrassetto\\OneDrive - Microsoft\\Desktop\\azure-notebooks\\.venv\\Lib\\site-packages\\azure\\ai\\projects\\operations\\_operations.py:1757\u001b[39m, in \u001b[36mAgentsOperations.create_agent\u001b[39m\u001b[34m(self, body, model, name, description, instructions, tools, tool_resources, temperature, top_p, response_format, metadata, **kwargs)\u001b[39m\n\u001b[32m   1755\u001b[39m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m   1756\u001b[39m     map_error(status_code=response.status_code, response=response, error_map=error_map)\n\u001b[32m-> \u001b[39m\u001b[32m1757\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HttpResponseError(response=response)\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _stream:\n\u001b[32m   1760\u001b[39m     deserialized = response.iter_bytes()\n",
      "\u001b[31mHttpResponseError\u001b[39m: (model_not_found_or_ready) The model deployment provided for this resource does not exist or is not yet ready. If you created the deployment within the last 5 minutes, please wait a moment and try again.\nCode: model_not_found_or_ready\nMessage: The model deployment provided for this resource does not exist or is not yet ready. If you created the deployment within the last 5 minutes, please wait a moment and try again."
     ]
    }
   ],
   "source": [
    "bing_connection = project_client.connections.get(\n",
    "    connection_name=os.environ[\"BING_CONNECTION_NAME\"]\n",
    ")\n",
    "conn_id = bing_connection.id\n",
    "\n",
    "print(conn_id)\n",
    "\n",
    "# Initialize agent bing tool and add the connection id\n",
    "bing = BingGroundingTool(connection_id=conn_id)\n",
    "\n",
    "# Create agent with the bing tool and process assistant run\n",
    "with project_client:\n",
    "    agent = project_client.agents.create_agent(\n",
    "        model=\"gpt-35-turbo\",\n",
    "        name=\"my-assistant\",\n",
    "        instructions=\"You are a helpful assistant\",\n",
    "        tools=bing.definitions,\n",
    "        headers={\"x-ms-enable-preview\": \"true\"}\n",
    "    )\n",
    "    print(f\"Created agent, ID: {agent.id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create thread for communication\n",
    "thread = project_client.agents.create_thread()\n",
    "print(f\"Created thread, ID: {thread.id}\")\n",
    "\n",
    "# Create message to thread\n",
    "message = project_client.agents.create_message(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"What is the top news today\",\n",
    ")\n",
    "print(f\"Created message, ID: {message.id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and process agent run in thread with tools\n",
    "run = project_client.agents.create_and_process_run(thread_id=thread.id, assistant_id=agent.id)\n",
    "print(f\"Run finished with status: {run.status}\")\n",
    "\n",
    "# Retrieve run step details to get Bing Search query link\n",
    "# To render the webpage, we recommend you replace the endpoint of Bing search query URLs with `www.bing.com` and your Bing search query URL would look like \"https://www.bing.com/search?q={search query}\"\n",
    "run_steps = project_client.agents.list_run_steps(run_id=run.id, thread_id=thread.id)\n",
    "run_steps_data = run_steps['data']\n",
    "print(f\"Last run step detail: {run_steps_data}\")\n",
    "\n",
    "if run.status == \"failed\":\n",
    "    print(f\"Run failed: {run.last_error}\")\n",
    "\n",
    "# Delete the assistant when done\n",
    "project_client.agents.delete_agent(agent.id)\n",
    "print(\"Deleted agent\")\n",
    "\n",
    "# Fetch and log all messages\n",
    "messages = project_client.agents.list_messages(thread_id=thread.id)\n",
    "print(f\"Messages: {messages}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Grounding with your files</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Upload files</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Azure Blob Storage</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Grounding with Azure AI Search</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.projects.models import AzureAISearchTool\n",
    "\n",
    "# Create an Azure AI Client from a connection string, copied from your Azure AI Foundry project.\n",
    "# At the moment, it should be in the format \"<HostName>;<AzureSubscriptionId>;<ResourceGroup>;<ProjectName>\"\n",
    "# HostName can be found by navigating to your discovery_url and removing the leading \"https://\" and trailing \"/discovery\" \n",
    "# To find your discovery_url, run the CLI command: az ml workspace show -n {project_name} --resource-group {resource_group_name} --query discovery_url\n",
    "# Project Connection example: eastus.api.azureml.ms;my-subscription-id;my-resource-group;my-hub-name\n",
    "\n",
    "connection_string = os.environ[\"PROJECT_CONNECTION_STRING\"] \n",
    "\n",
    "project_client = AIProjectClient.from_connection_string(\n",
    "    credential=DefaultAzureCredential(),\n",
    "    conn_str=connection_string,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AI Search resource connection ID\n",
    "# This code looks for the AI Search Connection ID and saves it as variable conn_id\n",
    "\n",
    "# If you have more than one AI search connection, try to establish the value in your .env file.\n",
    "# Extract the connection list.\n",
    "conn_list = project_client.connections._list_connections()[\"value\"]\n",
    "conn_id = \"\"\n",
    "\n",
    "# Search in the metadata field of each connection in the list for the azure_ai_search type and get the id value to establish the variable\n",
    "for conn in conn_list:\n",
    "    metadata = conn[\"properties\"].get(\"metadata\", {})\n",
    "    if metadata.get(\"type\", \"\").upper() == \"AZURE_AI_SEARCH\":\n",
    "        conn_id = conn[\"id\"]\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: replace this value with the connection ID of the search index\n",
    "conn_id =  \"/subscriptions/<your-subscription-id>/resourceGroups/<your-resource-group>/providers/Microsoft.MachineLearningServices/workspaces/<your-project-name>/connections/<your-azure-ai-search-connection-name>\"\n",
    "\n",
    "# Initialize agent AI search tool and add the search index connection ID and index name\n",
    "# TO DO: replace <your-index-name> with the name of the index you want to use\n",
    "ai_search = AzureAISearchTool(index_connection_id=conn_id, index_name=\"<your-index-name>\"\n",
    "query_type=\"<select-search-type>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = project_client.agents.create_agent(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    name=\"my-assistant\",\n",
    "    instructions=\"You are a helpful assistant\",\n",
    "    tools=ai_search.definitions,\n",
    "    tool_resources = ai_search.resources,\n",
    ")\n",
    "print(f\"Created agent, ID: {agent.id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "thread = project_client.agents.create_thread()\n",
    "print(f\"Created thread, thread ID: {thread.id}\")\n",
    " \n",
    "# Create a message\n",
    "message = project_client.agents.create_message(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"what are my health insurance plan coverage types?\",\n",
    ")\n",
    "print(f\"Created message, message ID: {message.id}\")\n",
    "    \n",
    "# Run the agent\n",
    "run = project_client.agents.create_and_process_run(thread_id=thread.id, assistant_id=agent.id)\n",
    "print(f\"Run finished with status: {run.status}\")\n",
    " \n",
    "if run.status == \"failed\":\n",
    "    # Check if you got \"Rate limit is exceeded.\", then you want to get more quota\n",
    "    print(f\"Run failed: {run.last_error}\")\n",
    "\n",
    "# Get messages from the thread \n",
    "messages = project_client.agents.list_messages(thread_id=thread.id)\n",
    "print(f\"Messages: {messages}\")\n",
    "    \n",
    "assistant_message = \"\"\n",
    "for message in messages.data:\n",
    "    if message[\"role\"] == \"assistant\":\n",
    "        assistant_message = message[\"content\"][0][\"text\"][\"value\"]\n",
    "\n",
    "# Get the last message from the sender\n",
    "print(f\"Assistant response: {assistant_message}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Using action tools</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Function calling</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import datetime\n",
    "from typing import Any, Callable, Set, Dict, List, Optional\n",
    "\n",
    "def fetch_weather(location: str) -> str:\n",
    "    \"\"\"\n",
    "    Fetches the weather information for the specified location.\n",
    "\n",
    "    :param location (str): The location to fetch weather for.\n",
    "    :return: Weather information as a JSON string.\n",
    "    :rtype: str\n",
    "    \"\"\"\n",
    "    # In a real-world scenario, you'd integrate with a weather API.\n",
    "    # Here, we'll mock the response.\n",
    "    mock_weather_data = {\"New York\": \"Sunny, 25°C\", \"London\": \"Cloudy, 18°C\", \"Tokyo\": \"Rainy, 22°C\"}\n",
    "    weather = mock_weather_data.get(location, \"Weather data not available for this location.\")\n",
    "    weather_json = json.dumps({\"weather\": weather})\n",
    "    return weather_json\n",
    "\n",
    "# Statically defined user functions for fast reference\n",
    "user_functions: Set[Callable[..., Any]] = {\n",
    "    fetch_weather,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created agent, ID: asst_k9t5tF5eHQjNY1Ef3UhREEZu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.projects.models import FunctionTool, ToolSet\n",
    "# from user_functions import user_functions # user functions which can be found in a user_functions.py file.\n",
    "\n",
    "# Create an Azure AI Client from a connection string, copied from your Azure AI Foundry project.\n",
    "# It should be in the format \"<HostName>;<AzureSubscriptionId>;<ResourceGroup>;<HubName>\"\n",
    "# Customers need to login to Azure subscription via Azure CLI and set the environment variables\n",
    "\n",
    "project_client = AIProjectClient.from_connection_string(\n",
    "    credential=DefaultAzureCredential(),\n",
    "    conn_str=os.environ[\"PROJECT_CONNECTION_STRING\"],\n",
    ")\n",
    "\n",
    "# Initialize agent toolset with user functions\n",
    "functions = FunctionTool(user_functions)\n",
    "toolset = ToolSet()\n",
    "toolset.add(functions)\n",
    "\n",
    "agent = project_client.agents.create_agent(\n",
    "    model=\"gpt-4o-mini\", name=\"my-agent\", instructions=\"You are a weather bot. Use the provided functions to help answer questions.\", toolset=toolset\n",
    ")\n",
    "print(f\"Created agent, ID: {agent.id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created thread, ID: thread_6XNicWkTaGJm4HXvoplWgaLp\n",
      "Created message, ID: msg_AdTOttFNpdAVy6LmJFauJomd\n"
     ]
    }
   ],
   "source": [
    "# Create thread for communication\n",
    "thread = project_client.agents.create_thread()\n",
    "print(f\"Created thread, ID: {thread.id}\")\n",
    "\n",
    "# Create message to thread\n",
    "message = project_client.agents.create_message(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"Hello, send an email with the datetime and weather information in Brussels?\",\n",
    ")\n",
    "print(f\"Created message, ID: {message.id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run finished with status: RunStatus.FAILED\n",
      "Run failed: {'code': 'rate_limit_exceeded', 'message': 'Rate limit is exceeded. Try again in 29 seconds.'}\n",
      "Deleted agent\n",
      "Messages: {'object': 'list', 'data': [{'id': 'msg_AdTOttFNpdAVy6LmJFauJomd', 'object': 'thread.message', 'created_at': 1741353974, 'assistant_id': None, 'thread_id': 'thread_6XNicWkTaGJm4HXvoplWgaLp', 'run_id': None, 'role': 'user', 'content': [{'type': 'text', 'text': {'value': 'Hello, send an email with the datetime and weather information in Brussels?', 'annotations': []}}], 'attachments': [], 'metadata': {}}], 'first_id': 'msg_AdTOttFNpdAVy6LmJFauJomd', 'last_id': 'msg_AdTOttFNpdAVy6LmJFauJomd', 'has_more': False}\n"
     ]
    }
   ],
   "source": [
    "# Create and process agent run in thread with tools\n",
    "run = project_client.agents.create_and_process_run(thread_id=thread.id, assistant_id=agent.id)\n",
    "print(f\"Run finished with status: {run.status}\")\n",
    "\n",
    "if run.status == \"failed\":\n",
    "    print(f\"Run failed: {run.last_error}\")\n",
    "\n",
    "# Delete the agent when done\n",
    "project_client.agents.delete_agent(agent.id)\n",
    "print(\"Deleted agent\")\n",
    "\n",
    "# Fetch and log all messages\n",
    "messages = project_client.agents.list_messages(thread_id=thread.id)\n",
    "print(f\"Messages: {messages}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[66]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Get the actual LLM completion message:\u001b[39;00m\n\u001b[32m      2\u001b[39m llm_completion_message = messages.get_last_text_message_by_role(\u001b[33m\"\u001b[39m\u001b[33massistant\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mllm_completion_message\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33mvalue\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[31mTypeError\u001b[39m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# Get the actual LLM completion message:\n",
    "llm_completion_message = messages.get_last_text_message_by_role(\"assistant\")\n",
    "print(llm_completion_message[\"text\"][\"value\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Code interpreter</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.ai.projects.models import CodeInterpreterTool\n",
    "from azure.ai.projects.models import FilePurpose\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from pathlib import Path\n",
    "\n",
    "# Create an Azure AI Client from a connection string, copied from your Azure AI Foundry project.\n",
    "# At the moment, it should be in the format \"<HostName>;<AzureSubscriptionId>;<ResourceGroup>;<HubName>\"\n",
    "# Customer needs to login to Azure subscription via Azure CLI and set the environment variables\n",
    "project_client = AIProjectClient.from_connection_string(\n",
    "    credential=DefaultAzureCredential(), conn_str=os.environ[\"PROJECT_CONNECTION_STRING\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded file, file ID: assistant-9VXexz54BAfZKpoUuL6AQi\n"
     ]
    }
   ],
   "source": [
    "# Upload a file and add it to the client \n",
    "path: str = r\"C:\\Users\\ngrassetto\\OneDrive - Microsoft\\Desktop\\azure-notebooks\\ai-agents\\vgsales.csv\"\n",
    "file = project_client.agents.upload_file_and_poll(\n",
    "    file_path=path, purpose=FilePurpose.AGENTS\n",
    ")\n",
    "print(f\"Uploaded file, file ID: {file.id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_interpreter = CodeInterpreterTool(file_ids=[file.id])\n",
    "\n",
    "# create agent with code interpreter tool and tools_resources\n",
    "agent = project_client.agents.create_agent(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    name=\"my-agent\",\n",
    "    instructions=\"You are helpful agent\",\n",
    "    tools=code_interpreter.definitions,\n",
    "    tool_resources=code_interpreter.resources,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created thread, thread ID: thread_vwXR6GmjHmuQAXtHGkuNvjjx\n",
      "Created message, message ID: msg_Xt2m1zf3yYRg35O2d5Vm7nTM\n",
      "Run finished with status: RunStatus.COMPLETED\n"
     ]
    }
   ],
   "source": [
    "# create a thread\n",
    "thread = project_client.agents.create_thread()\n",
    "print(f\"Created thread, thread ID: {thread.id}\")\n",
    "\n",
    "# create a message\n",
    "message = project_client.agents.create_message(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"Could you please create bar chart in the sales per genre from the uploaded csv file and provide file to me?\",\n",
    ")\n",
    "print(f\"Created message, message ID: {message.id}\")\n",
    "\n",
    "# create and execute a run\n",
    "run = project_client.agents.create_and_process_run(thread_id=thread.id, assistant_id=agent.id)\n",
    "print(f\"Run finished with status: {run.status}\")\n",
    "\n",
    "# if run.status == \"failed\":\n",
    "#     # Check if you got \"Rate limit is exceeded.\", then you want to get more quota\n",
    "#     print(f\"Run failed: {run.last_error}\")\n",
    "\n",
    "# # delete the original file from the agent to free up space (note: this does not delete your version of the file)\n",
    "# project_client.agents.delete_file(file.id)\n",
    "# print(\"Deleted file\")\n",
    "\n",
    "# # print the messages from the agent\n",
    "# messages = project_client.agents.list_messages(thread_id=thread.id)\n",
    "# print(f\"Messages: {messages}\")\n",
    "\n",
    "# # get the most recent message from the assistant\n",
    "# last_msg = messages.get_last_text_message_by_sender(\"assistant\")\n",
    "# if last_msg:\n",
    "#     print(f\"Last Message: {last_msg.text.value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image File ID: assistant-GVFqap15pumj4qRHXx3inB\n",
      "Saved image file to: c:\\Users\\ngrassetto\\OneDrive - Microsoft\\Desktop\\azure-notebooks\\ai-agents\\assistant-GVFqap15pumj4qRHXx3inB_image_file.png\n"
     ]
    }
   ],
   "source": [
    "# save the newly created file\n",
    "for image_content in messages.image_contents:\n",
    "  print(f\"Image File ID: {image_content.image_file.file_id}\")\n",
    "  file_name = f\"{image_content.image_file.file_id}_image_file.png\"\n",
    "  project_client.agents.save_file(file_id=image_content.image_file.file_id, file_name=file_name)\n",
    "  print(f\"Saved image file to: {Path.cwd() / file_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>OpenAI defined tools</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Azure Functions</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the weather from an Azure Storage queue where the AI Agent will send function call information\n",
    "# It returns the mock weather to an output queue with the correlation id for the AI Agent Service to pick up the result of the function call\n",
    "@app.function_name(name=\"GetWeather\")\n",
    "@app.queue_trigger(arg_name=\"msg\", queue_name=\"input\", connection=\"STORAGE_CONNECTION\")  \n",
    "def process_queue_message(msg: func.QueueMessage) -> None:\n",
    "    logging.info('Python queue trigger function processed a queue item')\n",
    "\n",
    "    # Queue to send message to\n",
    "    queue_client = QueueClient(\n",
    "        os.environ[\"STORAGE_CONNECTION__queueServiceUri\"],\n",
    "        queue_name=\"output\",\n",
    "        credential=DefaultAzureCredential(),\n",
    "        message_encode_policy=BinaryBase64EncodePolicy(),\n",
    "        message_decode_policy=BinaryBase64DecodePolicy()\n",
    "    )\n",
    "\n",
    "    # Get the content of the function call message\n",
    "    messagepayload = json.loads(msg.get_body().decode('utf-8'))\n",
    "    location = messagepayload['location']\n",
    "    correlation_id = messagepayload['CorrelationId']\n",
    "\n",
    "    # Send message to queue. Sends a mock message for the weather\n",
    "    result_message = {\n",
    "        'Value': 'Weather is 74 degrees and sunny in ' + location,\n",
    "        'CorrelationId': correlation_id\n",
    "    }\n",
    "    queue_client.send_message(json.dumps(result_message).encode('utf-8'))\n",
    "\n",
    "    logging.info(f\"Sent message to output queue with message {result_message}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the client and create agent for the tools Azure Functions that the agent can use\n",
    "\n",
    "# Create a project client\n",
    "project_client = AIProjectClient.from_connection_string(\n",
    "    credential=DefaultAzureCredential(),\n",
    "    conn_str=os.environ[\"PROJECT_CONNECTION_STRING\"]\n",
    ")\n",
    "\n",
    "# Get the connection string for the storage account to send and receive the function calls to the queues\n",
    "storage_connection_string = os.environ[\"STORAGE_CONNECTION__queueServiceUri\"]\n",
    "\n",
    "# Create an agent with the Azure Function tool to get the weather\n",
    "agent = project_client.agents.create_agent(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    name=\"azure-function-agent-get-weather\",\n",
    "    instructions=\"You are a helpful support agent. Answer the user's questions to the best of your ability.\",\n",
    "    headers={\"x-ms-enable-preview\": \"true\"},\n",
    "    tools=[\n",
    "        {\n",
    "            \"type\": \"azure_function\",\n",
    "            \"azure_function\": {\n",
    "                \"function\": {\n",
    "                    \"name\": \"GetWeather\",\n",
    "                    \"description\": \"Get the weather in a location.\",\n",
    "                    \"parameters\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"location\": {\"type\": \"string\", \"description\": \"The location to look up.\"}\n",
    "                        },\n",
    "                        \"required\": [\"location\"]\n",
    "                    }\n",
    "                },\n",
    "                \"input_binding\": {\n",
    "                    \"type\": \"storage_queue\",\n",
    "                    \"storage_queue\": {\n",
    "                        \"queue_service_uri\": storage_connection_string,\n",
    "                        \"queue_name\": \"input\"\n",
    "                    }\n",
    "                },\n",
    "                \"output_binding\": {\n",
    "                    \"type\": \"storage_queue\",\n",
    "                    \"storage_queue\": {\n",
    "                        \"queue_service_uri\": storage_connection_string,\n",
    "                        \"queue_name\": \"output\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Using enterprise features</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Using your own resources</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Tracing with Application Insights</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Content filtering </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Using virtual networks</h3>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
