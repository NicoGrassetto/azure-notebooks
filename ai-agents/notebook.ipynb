{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Azure AI Agent Service </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Deploying an agent with infrastructure as code</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Creating a simple agent</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\ngrassetto\\onedrive - microsoft\\desktop\\azure-notebooks\\.venv\\lib\\site-packages (24.0)\n",
      "Collecting pip\n",
      "  Downloading pip-25.0.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Downloading pip-25.0.1-py3-none-any.whl (1.8 MB)\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.0/1.8 MB 279.3 kB/s eta 0:00:07\n",
      "   -- ------------------------------------- 0.1/1.8 MB 581.0 kB/s eta 0:00:04\n",
      "   -------- ------------------------------- 0.4/1.8 MB 1.8 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.1/1.8 MB 4.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.8/1.8 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.8/1.8 MB 5.9 MB/s eta 0:00:00\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 24.0\n",
      "    Uninstalling pip-24.0:\n",
      "      Successfully uninstalled pip-24.0\n",
      "Successfully installed pip-25.0.1\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\ngrassetto\\onedrive - microsoft\\desktop\\azure-notebooks\\.venv\\lib\\site-packages (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "# !pip install azure-ai-projects\n",
    "# !pip install azure-identity\n",
    "# !python.exe -m pip install --upgrade pip\n",
    "# !pip install python-dotenv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created agent, agent ID: asst_4bUsle9VtUUKHM4R9qt8pIaz\n",
      "Created thread, thread ID: thread_vGkUyo9iWrXGsxghNmiiLGGm\n",
      "Created message, message ID: msg_rF3rn31nVYcGzXxpsKXK3PYN\n",
      "Run finished with status: RunStatus.COMPLETED\n",
      "Messages: {'object': 'list', 'data': [{'id': 'msg_BKN7qvTWN44Ts8dEOuccCSJd', 'object': 'thread.message', 'created_at': 1741345692, 'assistant_id': 'asst_4bUsle9VtUUKHM4R9qt8pIaz', 'thread_id': 'thread_vGkUyo9iWrXGsxghNmiiLGGm', 'run_id': 'run_BhbbS4oyrULVUBFxeWboN93b', 'role': 'assistant', 'content': [{'type': 'image_file', 'image_file': {'file_id': 'assistant-3u5c14EihWjQLXQiwZTouH'}}, {'type': 'text', 'text': {'value': \"I've created the bar chart for the operating profits of the companies. You can download it using the link below:\\n\\n[Download the operating profit bar chart](sandbox:/mnt/data/operating_profit_bar_chart.png)\", 'annotations': [{'type': 'file_path', 'text': 'sandbox:/mnt/data/operating_profit_bar_chart.png', 'start_index': 156, 'end_index': 204, 'file_path': {'file_id': 'assistant-9uusGSM41GjT3tGm2jF8v9'}}]}}], 'attachments': [{'file_id': 'assistant-9uusGSM41GjT3tGm2jF8v9', 'tools': [{'type': 'code_interpreter'}]}], 'metadata': {}}, {'id': 'msg_rF3rn31nVYcGzXxpsKXK3PYN', 'object': 'thread.message', 'created_at': 1741345681, 'assistant_id': None, 'thread_id': 'thread_vGkUyo9iWrXGsxghNmiiLGGm', 'run_id': None, 'role': 'user', 'content': [{'type': 'text', 'text': {'value': 'Could you please create a bar chart for the operating profit using the following data and provide the file to me? Company A: $1.2 million, Company B: $2.5 million, Company C: $3.0 million, Company D: $1.8 million', 'annotations': []}}], 'attachments': [], 'metadata': {}}], 'first_id': 'msg_BKN7qvTWN44Ts8dEOuccCSJd', 'last_id': 'msg_rF3rn31nVYcGzXxpsKXK3PYN', 'has_more': False}\n",
      "Last Message: I've created the bar chart for the operating profits of the companies. You can download it using the link below:\n",
      "\n",
      "[Download the operating profit bar chart](sandbox:/mnt/data/operating_profit_bar_chart.png)\n",
      "Image File ID: assistant-3u5c14EihWjQLXQiwZTouH\n",
      "Saved image file to: c:\\Users\\ngrassetto\\OneDrive - Microsoft\\Desktop\\azure-notebooks\\ai-agents\\assistant-3u5c14EihWjQLXQiwZTouH_image_file.png\n",
      "File Paths:\n",
      "Type: file_path\n",
      "Text: sandbox:/mnt/data/operating_profit_bar_chart.png\n",
      "File ID: assistant-9uusGSM41GjT3tGm2jF8v9\n",
      "Start Index: 156\n",
      "End Index: 204\n",
      "Deleted agent\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.ai.projects.models import CodeInterpreterTool\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from typing import Any\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Create an Azure AI Client from a connection string, copied from your Azure AI Foundry project.\n",
    "# At the moment, it should be in the format \"<HostName>;<AzureSubscriptionId>;<ResourceGroup>;<ProjectName>\"\n",
    "# HostName can be found by navigating to your discovery_url and removing the leading \"https://\" and trailing \"/discovery\"\n",
    "# To find your discovery_url, run the CLI command: az ml workspace show -n {project_name} --resource-group {resource_group_name} --query discovery_url\n",
    "# Project Connection example: eastus.api.azureml.ms;12345678-abcd-1234-9fc6-62780b3d3e05;my-resource-group;my-project-name\n",
    "# Customer needs to login to Azure subscription via Azure CLI and set the environment variables\n",
    "\n",
    "project_client = AIProjectClient.from_connection_string(\n",
    "    credential=DefaultAzureCredential(), conn_str=os.environ.get(\"PROJECT_CONNECTION_STRING\")\n",
    ")\n",
    "\n",
    "with project_client:\n",
    "    # Create an instance of the CodeInterpreterTool\n",
    "    code_interpreter = CodeInterpreterTool()\n",
    "\n",
    "    # The CodeInterpreterTool needs to be included in creation of the agent\n",
    "    agent = project_client.agents.create_agent(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        name=\"my-agent\",\n",
    "        instructions=\"You are helpful agent\",\n",
    "        tools=code_interpreter.definitions,\n",
    "        tool_resources=code_interpreter.resources,\n",
    "    )\n",
    "    print(f\"Created agent, agent ID: {agent.id}\")\n",
    "\n",
    "    # Create a thread\n",
    "    thread = project_client.agents.create_thread()\n",
    "    print(f\"Created thread, thread ID: {thread.id}\")\n",
    "\n",
    "    # Create a message\n",
    "    message = project_client.agents.create_message(\n",
    "        thread_id=thread.id,\n",
    "        role=\"user\",\n",
    "        content=\"Could you please create a bar chart for the operating profit using the following data and provide the file to me? Company A: $1.2 million, Company B: $2.5 million, Company C: $3.0 million, Company D: $1.8 million\",\n",
    "    )\n",
    "    print(f\"Created message, message ID: {message.id}\")\n",
    "\n",
    "    # Run the agent\n",
    "    run = project_client.agents.create_and_process_run(thread_id=thread.id, assistant_id=agent.id)\n",
    "    print(f\"Run finished with status: {run.status}\")\n",
    "\n",
    "    if run.status == \"failed\":\n",
    "        # Check if you got \"Rate limit is exceeded.\", then you want to get more quota\n",
    "        print(f\"Run failed: {run.last_error}\")\n",
    "\n",
    "    # Get messages from the thread\n",
    "    messages = project_client.agents.list_messages(thread_id=thread.id)\n",
    "    print(f\"Messages: {messages}\")\n",
    "\n",
    "    # Get the last message from the sender\n",
    "    last_msg = messages.get_last_text_message_by_role(\"assistant\")\n",
    "    if last_msg:\n",
    "        print(f\"Last Message: {last_msg.text.value}\")\n",
    "\n",
    "    # Generate an image file for the bar chart\n",
    "    for image_content in messages.image_contents:\n",
    "        print(f\"Image File ID: {image_content.image_file.file_id}\")\n",
    "        file_name = f\"{image_content.image_file.file_id}_image_file.png\"\n",
    "        project_client.agents.save_file(file_id=image_content.image_file.file_id, file_name=file_name)\n",
    "        print(f\"Saved image file to: {Path.cwd() / file_name}\")\n",
    "\n",
    "    # Print the file path(s) from the messages\n",
    "    for file_path_annotation in messages.file_path_annotations:\n",
    "        print(f\"File Paths:\")\n",
    "        print(f\"Type: {file_path_annotation.type}\")\n",
    "        print(f\"Text: {file_path_annotation.text}\")\n",
    "        print(f\"File ID: {file_path_annotation.file_path.file_id}\")\n",
    "        print(f\"Start Index: {file_path_annotation.start_index}\")\n",
    "        print(f\"End Index: {file_path_annotation.end_index}\")\n",
    "        project_client.agents.save_file(file_id=file_path_annotation.file_path.file_id, file_name=Path(file_path_annotation.text).name)\n",
    "\n",
    "    # Delete the agent once done\n",
    "    project_client.agents.delete_agent(agent.id)\n",
    "    print(\"Deleted agent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Using knowledge tools</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Grounding with Bing Search</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an Azure AI Client from a connection string, copied from your Azure AI Foundry project.</br>\n",
    "At the moment, it should be in the format \"<HostName>;<AzureSubscriptionId>;<ResourceGroup>;<HubName>\"</br>\n",
    "You need to log into your Azure subscription via the Azure CLI and set the relevant environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.projects.models import BingGroundingTool\n",
    "\n",
    "project_client = AIProjectClient.from_connection_string(\n",
    "    credential=DefaultAzureCredential(),\n",
    "    conn_str=os.environ[\"PROJECT_CONNECTION_STRING\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "HttpResponseError",
     "evalue": "(model_not_found_or_ready) The model deployment provided for this resource does not exist or is not yet ready. If you created the deployment within the last 5 minutes, please wait a moment and try again.\nCode: model_not_found_or_ready\nMessage: The model deployment provided for this resource does not exist or is not yet ready. If you created the deployment within the last 5 minutes, please wait a moment and try again.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHttpResponseError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Create agent with the bing tool and process assistant run\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m project_client:\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     agent = \u001b[43mproject_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43magents\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_agent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmy-assistant\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m        \u001b[49m\u001b[43minstructions\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mYou are a helpful assistant\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbing\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdefinitions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mx-ms-enable-preview\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrue\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCreated agent, ID: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00magent.id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ngrassetto\\OneDrive - Microsoft\\Desktop\\azure-notebooks\\.venv\\Lib\\site-packages\\azure\\core\\tracing\\decorator.py:105\u001b[39m, in \u001b[36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    103\u001b[39m span_impl_type = settings.tracing_implementation()\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m span_impl_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[32m    108\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m merge_span \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m passed_in_parent:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ngrassetto\\OneDrive - Microsoft\\Desktop\\azure-notebooks\\.venv\\Lib\\site-packages\\azure\\ai\\projects\\operations\\_patch.py:1062\u001b[39m, in \u001b[36mAgentsOperations.create_agent\u001b[39m\u001b[34m(self, body, model, name, description, instructions, tools, tool_resources, toolset, temperature, top_p, response_format, metadata, content_type, **kwargs)\u001b[39m\n\u001b[32m   1059\u001b[39m     tools = toolset.definitions\n\u001b[32m   1060\u001b[39m     tool_resources = toolset.resources\n\u001b[32m-> \u001b[39m\u001b[32m1062\u001b[39m new_agent = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_agent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1063\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1064\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1065\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1066\u001b[39m \u001b[43m    \u001b[49m\u001b[43minstructions\u001b[49m\u001b[43m=\u001b[49m\u001b[43minstructions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1067\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1068\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtool_resources\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtool_resources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1069\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1070\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1071\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1072\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1073\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1074\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1076\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m toolset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1077\u001b[39m     \u001b[38;5;28mself\u001b[39m._toolset[new_agent.id] = toolset\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ngrassetto\\OneDrive - Microsoft\\Desktop\\azure-notebooks\\.venv\\Lib\\site-packages\\azure\\core\\tracing\\decorator.py:105\u001b[39m, in \u001b[36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    103\u001b[39m span_impl_type = settings.tracing_implementation()\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m span_impl_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[32m    108\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m merge_span \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m passed_in_parent:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ngrassetto\\OneDrive - Microsoft\\Desktop\\azure-notebooks\\.venv\\Lib\\site-packages\\azure\\ai\\projects\\operations\\_operations.py:1757\u001b[39m, in \u001b[36mAgentsOperations.create_agent\u001b[39m\u001b[34m(self, body, model, name, description, instructions, tools, tool_resources, temperature, top_p, response_format, metadata, **kwargs)\u001b[39m\n\u001b[32m   1755\u001b[39m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m   1756\u001b[39m     map_error(status_code=response.status_code, response=response, error_map=error_map)\n\u001b[32m-> \u001b[39m\u001b[32m1757\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HttpResponseError(response=response)\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _stream:\n\u001b[32m   1760\u001b[39m     deserialized = response.iter_bytes()\n",
      "\u001b[31mHttpResponseError\u001b[39m: (model_not_found_or_ready) The model deployment provided for this resource does not exist or is not yet ready. If you created the deployment within the last 5 minutes, please wait a moment and try again.\nCode: model_not_found_or_ready\nMessage: The model deployment provided for this resource does not exist or is not yet ready. If you created the deployment within the last 5 minutes, please wait a moment and try again."
     ]
    }
   ],
   "source": [
    "bing_connection = project_client.connections.get(\n",
    "    connection_name=os.environ[\"BING_CONNECTION_NAME\"]\n",
    ")\n",
    "conn_id = bing_connection.id\n",
    "\n",
    "print(conn_id)\n",
    "\n",
    "# Initialize agent bing tool and add the connection id\n",
    "bing = BingGroundingTool(connection_id=conn_id)\n",
    "\n",
    "# Create agent with the bing tool and process assistant run\n",
    "with project_client:\n",
    "    agent = project_client.agents.create_agent(\n",
    "        model=\"gpt-35-turbo\",\n",
    "        name=\"my-assistant\",\n",
    "        instructions=\"You are a helpful assistant\",\n",
    "        tools=bing.definitions,\n",
    "        headers={\"x-ms-enable-preview\": \"true\"}\n",
    "    )\n",
    "    print(f\"Created agent, ID: {agent.id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create thread for communication\n",
    "thread = project_client.agents.create_thread()\n",
    "print(f\"Created thread, ID: {thread.id}\")\n",
    "\n",
    "# Create message to thread\n",
    "message = project_client.agents.create_message(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"What is the top news today\",\n",
    ")\n",
    "print(f\"Created message, ID: {message.id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and process agent run in thread with tools\n",
    "run = project_client.agents.create_and_process_run(thread_id=thread.id, assistant_id=agent.id)\n",
    "print(f\"Run finished with status: {run.status}\")\n",
    "\n",
    "# Retrieve run step details to get Bing Search query link\n",
    "# To render the webpage, we recommend you replace the endpoint of Bing search query URLs with `www.bing.com` and your Bing search query URL would look like \"https://www.bing.com/search?q={search query}\"\n",
    "run_steps = project_client.agents.list_run_steps(run_id=run.id, thread_id=thread.id)\n",
    "run_steps_data = run_steps['data']\n",
    "print(f\"Last run step detail: {run_steps_data}\")\n",
    "\n",
    "if run.status == \"failed\":\n",
    "    print(f\"Run failed: {run.last_error}\")\n",
    "\n",
    "# Delete the assistant when done\n",
    "project_client.agents.delete_agent(agent.id)\n",
    "print(\"Deleted agent\")\n",
    "\n",
    "# Fetch and log all messages\n",
    "messages = project_client.agents.list_messages(thread_id=thread.id)\n",
    "print(f\"Messages: {messages}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Grounding with your files</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Upload files</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Azure Blob Storage</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Grounding with Azure AI Search</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.projects.models import AzureAISearchTool\n",
    "\n",
    "# Create an Azure AI Client from a connection string, copied from your Azure AI Foundry project.\n",
    "# At the moment, it should be in the format \"<HostName>;<AzureSubscriptionId>;<ResourceGroup>;<ProjectName>\"\n",
    "# HostName can be found by navigating to your discovery_url and removing the leading \"https://\" and trailing \"/discovery\" \n",
    "# To find your discovery_url, run the CLI command: az ml workspace show -n {project_name} --resource-group {resource_group_name} --query discovery_url\n",
    "# Project Connection example: eastus.api.azureml.ms;my-subscription-id;my-resource-group;my-hub-name\n",
    "\n",
    "connection_string = os.environ[\"PROJECT_CONNECTION_STRING\"] \n",
    "\n",
    "project_client = AIProjectClient.from_connection_string(\n",
    "    credential=DefaultAzureCredential(),\n",
    "    conn_str=connection_string,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AI Search resource connection ID\n",
    "# This code looks for the AI Search Connection ID and saves it as variable conn_id\n",
    "\n",
    "# If you have more than one AI search connection, try to establish the value in your .env file.\n",
    "# Extract the connection list.\n",
    "conn_list = project_client.connections._list_connections()[\"value\"]\n",
    "conn_id = \"\"\n",
    "\n",
    "# Search in the metadata field of each connection in the list for the azure_ai_search type and get the id value to establish the variable\n",
    "for conn in conn_list:\n",
    "    metadata = conn[\"properties\"].get(\"metadata\", {})\n",
    "    if metadata.get(\"type\", \"\").upper() == \"AZURE_AI_SEARCH\":\n",
    "        conn_id = conn[\"id\"]\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: replace this value with the connection ID of the search index\n",
    "conn_id =  \"/subscriptions/<your-subscription-id>/resourceGroups/<your-resource-group>/providers/Microsoft.MachineLearningServices/workspaces/<your-project-name>/connections/<your-azure-ai-search-connection-name>\"\n",
    "\n",
    "# Initialize agent AI search tool and add the search index connection ID and index name\n",
    "# TO DO: replace <your-index-name> with the name of the index you want to use\n",
    "ai_search = AzureAISearchTool(index_connection_id=conn_id, index_name=\"<your-index-name>\"\n",
    "query_type=\"<select-search-type>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = project_client.agents.create_agent(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    name=\"my-assistant\",\n",
    "    instructions=\"You are a helpful assistant\",\n",
    "    tools=ai_search.definitions,\n",
    "    tool_resources = ai_search.resources,\n",
    ")\n",
    "print(f\"Created agent, ID: {agent.id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "thread = project_client.agents.create_thread()\n",
    "print(f\"Created thread, thread ID: {thread.id}\")\n",
    " \n",
    "# Create a message\n",
    "message = project_client.agents.create_message(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"what are my health insurance plan coverage types?\",\n",
    ")\n",
    "print(f\"Created message, message ID: {message.id}\")\n",
    "    \n",
    "# Run the agent\n",
    "run = project_client.agents.create_and_process_run(thread_id=thread.id, assistant_id=agent.id)\n",
    "print(f\"Run finished with status: {run.status}\")\n",
    " \n",
    "if run.status == \"failed\":\n",
    "    # Check if you got \"Rate limit is exceeded.\", then you want to get more quota\n",
    "    print(f\"Run failed: {run.last_error}\")\n",
    "\n",
    "# Get messages from the thread \n",
    "messages = project_client.agents.list_messages(thread_id=thread.id)\n",
    "print(f\"Messages: {messages}\")\n",
    "    \n",
    "assistant_message = \"\"\n",
    "for message in messages.data:\n",
    "    if message[\"role\"] == \"assistant\":\n",
    "        assistant_message = message[\"content\"][0][\"text\"][\"value\"]\n",
    "\n",
    "# Get the last message from the sender\n",
    "print(f\"Assistant response: {assistant_message}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Using action tools</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Function calling</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import datetime\n",
    "from typing import Any, Callable, Set, Dict, List, Optional\n",
    "\n",
    "def fetch_weather(location: str) -> str:\n",
    "    \"\"\"\n",
    "    Fetches the weather information for the specified location.\n",
    "\n",
    "    :param location (str): The location to fetch weather for.\n",
    "    :return: Weather information as a JSON string.\n",
    "    :rtype: str\n",
    "    \"\"\"\n",
    "    # In a real-world scenario, you'd integrate with a weather API.\n",
    "    # Here, we'll mock the response.\n",
    "    mock_weather_data = {\"New York\": \"Sunny, 25°C\", \"London\": \"Cloudy, 18°C\", \"Tokyo\": \"Rainy, 22°C\"}\n",
    "    weather = mock_weather_data.get(location, \"Weather data not available for this location.\")\n",
    "    weather_json = json.dumps({\"weather\": weather})\n",
    "    return weather_json\n",
    "\n",
    "# Statically defined user functions for fast reference\n",
    "user_functions: Set[Callable[..., Any]] = {\n",
    "    fetch_weather,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created agent, ID: asst_BJ2u2TabJ3sXP5SRoai7DNUD\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.projects.models import FunctionTool, ToolSet\n",
    "# from user_functions import user_functions # user functions which can be found in a user_functions.py file.\n",
    "\n",
    "# Create an Azure AI Client from a connection string, copied from your Azure AI Foundry project.\n",
    "# It should be in the format \"<HostName>;<AzureSubscriptionId>;<ResourceGroup>;<HubName>\"\n",
    "# Customers need to login to Azure subscription via Azure CLI and set the environment variables\n",
    "\n",
    "project_client = AIProjectClient.from_connection_string(\n",
    "    credential=DefaultAzureCredential(),\n",
    "    conn_str=os.environ[\"PROJECT_CONNECTION_STRING\"],\n",
    ")\n",
    "\n",
    "# Initialize agent toolset with user functions\n",
    "functions = FunctionTool(user_functions)\n",
    "toolset = ToolSet()\n",
    "toolset.add(functions)\n",
    "\n",
    "agent = project_client.agents.create_agent(\n",
    "    model=\"gpt-4o-mini\", name=\"my-agent\", instructions=\"You are a weather bot. Use the provided functions to help answer questions.\", toolset=toolset\n",
    ")\n",
    "print(f\"Created agent, ID: {agent.id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created thread, ID: thread_T6wtYaDYXqg4p2lDniSog5eZ\n",
      "Created message, ID: msg_vQdetwJ7D5V7AXVC6OtSmomk\n"
     ]
    }
   ],
   "source": [
    "# Create thread for communication\n",
    "thread = project_client.agents.create_thread()\n",
    "print(f\"Created thread, ID: {thread.id}\")\n",
    "\n",
    "# Create message to thread\n",
    "message = project_client.agents.create_message(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"Hello, send an email with the datetime and weather information in Brussels?\",\n",
    ")\n",
    "print(f\"Created message, ID: {message.id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run finished with status: RunStatus.COMPLETED\n",
      "Deleted agent\n",
      "Messages: {'object': 'list', 'data': [{'id': 'msg_9CAE9idtk2zKfQcELLjrkTVe', 'object': 'thread.message', 'created_at': 1741353948, 'assistant_id': 'asst_BJ2u2TabJ3sXP5SRoai7DNUD', 'thread_id': 'thread_T6wtYaDYXqg4p2lDniSog5eZ', 'run_id': 'run_RVHglUKMIEktNGHUBwVMHvE2', 'role': 'assistant', 'content': [{'type': 'text', 'text': {'value': \"It seems that I'm unable to retrieve the weather information for Brussels, Belgium at the moment. However, the current date and time is something I can provide. \\n\\nWould you like me to send an email with just the current datetime, or do you have any other specific requests?\", 'annotations': []}}], 'attachments': [], 'metadata': {}}, {'id': 'msg_vQdetwJ7D5V7AXVC6OtSmomk', 'object': 'thread.message', 'created_at': 1741353944, 'assistant_id': None, 'thread_id': 'thread_T6wtYaDYXqg4p2lDniSog5eZ', 'run_id': None, 'role': 'user', 'content': [{'type': 'text', 'text': {'value': 'Hello, send an email with the datetime and weather information in Belgium, Brussels?', 'annotations': []}}], 'attachments': [], 'metadata': {}}], 'first_id': 'msg_9CAE9idtk2zKfQcELLjrkTVe', 'last_id': 'msg_vQdetwJ7D5V7AXVC6OtSmomk', 'has_more': False}\n"
     ]
    }
   ],
   "source": [
    "# Create and process agent run in thread with tools\n",
    "run = project_client.agents.create_and_process_run(thread_id=thread.id, assistant_id=agent.id)\n",
    "print(f\"Run finished with status: {run.status}\")\n",
    "\n",
    "if run.status == \"failed\":\n",
    "    print(f\"Run failed: {run.last_error}\")\n",
    "\n",
    "# Delete the agent when done\n",
    "project_client.agents.delete_agent(agent.id)\n",
    "print(\"Deleted agent\")\n",
    "\n",
    "# Fetch and log all messages\n",
    "messages = project_client.agents.list_messages(thread_id=thread.id)\n",
    "print(f\"Messages: {messages}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It seems that I'm unable to retrieve the weather information for Brussels, Belgium at the moment. However, the current date and time is something I can provide. \n",
      "\n",
      "Would you like me to send an email with just the current datetime, or do you have any other specific requests?\n"
     ]
    }
   ],
   "source": [
    "# Get the actual LLM completion message:\n",
    "llm_completion_message = messages.get_last_text_message_by_role(\"assistant\")\n",
    "print(llm_completion_message[\"text\"][\"value\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Code interpreter</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>OpenAI defined tools</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Azure Functions</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Using enterprise features</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Using your own resources</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Tracing with Application Insights</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Content filtering </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Using virtual networks</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
